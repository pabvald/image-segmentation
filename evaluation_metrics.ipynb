{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation metrics for the Cityscapes dataset\n",
    "In this Jupyter Notebook we show how to compute and visualize different evaluation metrics for the Cityscapes Pixel-Segmentation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cityscapesscripts\n",
      "  Downloading cityscapesScripts-2.2.0-py3-none-any.whl (472 kB)\n",
      "\u001b[K     |████████████████████████████████| 472 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting coloredlogs\n",
      "  Downloading coloredlogs-15.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from cityscapesscripts) (3.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from cityscapesscripts) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from cityscapesscripts) (4.31.1)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.6/site-packages (from cityscapesscripts) (1.4.4)\n",
      "Requirement already satisfied: typing in /opt/conda/lib/python3.6/site-packages (from cityscapesscripts) (3.7.4.1)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-8.1.2-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyquaternion\n",
      "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-9.1-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->cityscapesscripts) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->cityscapesscripts) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->cityscapesscripts) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->cityscapesscripts) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->cityscapesscripts) (1.15.0)\n",
      "Installing collected packages: humanfriendly, coloredlogs, pillow, pyquaternion, cityscapesscripts\n",
      "Successfully installed cityscapesscripts-2.2.0 coloredlogs-15.0 humanfriendly-9.1 pillow-8.1.2 pyquaternion-0.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install cityscapesscripts;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics\n",
    "from importlib import reload\n",
    "from os.path import join as pjoin\n",
    "from datasets.cityscapes import cityscapesDataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"./Cityscapes\"\n",
    "pckgs_names = [\"gtFine_trainvaltest.zip\",\"leftImg8bit_trainvaltest.zip\"]\n",
    "dir_names = [\"gtFine\", \"leftImg8bit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "We assume that the datset *Cityscapes* has already been downloaded in the folder *local_path*. If this is not the case, check first the notebook [Exploring the Cityscapes dataset](./Cytyscapes_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations files processed\n"
     ]
    }
   ],
   "source": [
    "training_data = cityscapesDataset(local_path, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 255]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = training_data.label_ids()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.isin(np.array(labels), 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lbl = training_data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2048])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [training_data[i][1] for i in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [training_data[i][1] for i in range(15,25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/project/simple-imageseg/evaluation.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import evaluation\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an evaluation report providing a dataloader and a model to make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an evaluation report providing the ground-truth values and the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluation.EvaluationReport.from_predictions(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7431,\n",
       " 'sensitivity': 0.6956,\n",
       " 'specificity': 0.7579,\n",
       " 'dice_coeff': 0.5626,\n",
       " 'jaccard_sim': 0.3914,\n",
       " 'f1_score': 0.5626}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class = 2\n",
    "metrics2 = evaluation.all_metrics(target_class)\n",
    "metrics2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of decimal places can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.74,\n",
       " 'sensitivity': 0.7,\n",
       " 'specificity': 0.76,\n",
       " 'dice_coeff': 0.56,\n",
       " 'jaccard_sim': 0.39,\n",
       " 'f1_score': 0.56}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.decimal_places = 2\n",
    "evaluation.all_metrics(target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_b = []\n",
    "y_true_b = [] \n",
    "for i in range(len(y_true)):\n",
    "    y_true_b.append((y_true[i] == target_class).long().flatten().numpy())\n",
    "    y_pred_b.append((y_pred[i] == target_class).long().flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_b  = np.concatenate(y_true_b, axis=None)\n",
    "y_pred_b  = np.concatenate(y_pred_b, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7431"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_accuracy = round(sklearn.metrics.accuracy_score(y_true_b, y_pred_b), 4)\n",
    "sk_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics2['accuracy'] == sk_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3914"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_js = round(sklearn.metrics.jaccard_score(y_true_b, y_pred_b), 4)\n",
    "sk_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics2['jaccard_sim'] == sk_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5626"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_f1 = round(sklearn.metrics.f1_score(y_true_b, y_pred_b), 4)\n",
    "sk_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics2['f1_score'] == sk_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics2['dice_coeff'] == sk_f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
